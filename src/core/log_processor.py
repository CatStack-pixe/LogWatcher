from pathlib import Path
from typing import List, Tuple, Optional
from .file_handler import FileHandler

class LogProcessor:
    def __init__(self, app_instance=None):
        self.app = app_instance
        self.processing_stats = {"total": 0, "matched": 0}
        self.file_handler = FileHandler()

    def filter_log(self, 
                  input_path: Path, 
                  output_path: Optional[Path],
                  keywords: str,
                  ignore_case: bool,
                  read_enc: str = None,
                  write_enc: str = None,
                  filter_fields: str = "",
                  enable_field_filter: bool = False,
                  preview_mode: bool = False) -> Tuple[int, int]:
        """å¤„ç†å•ä¸ªæ—¥å¿—æ–‡ä»¶"""
        try:
            if not input_path.exists():
                if self.app:
                    self.app.log_error(f"âŒ é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼š{input_path}")
                return (0, 0)

            # å¦‚æœæœªæŒ‡å®šç¼–ç ï¼Œè‡ªåŠ¨æ£€æµ‹
            if read_enc == 'auto' or not read_enc:
                read_enc = FileHandler.detect_encoding(input_path)
                if self.app:
                    self.app.log_info(f"ğŸ“ æ£€æµ‹åˆ°æ–‡ä»¶ç¼–ç : {read_enc}")

            # å¦‚æœæ˜¯é¢„è§ˆæ¨¡å¼ï¼Œä½¿ç”¨ç›¸åŒçš„ç¼–ç 
            if preview_mode:
                write_enc = read_enc
            elif not write_enc:
                write_enc = read_enc

            if output_path:
                output_path.parent.mkdir(parents=True, exist_ok=True)

            # åˆ†å‰²å…³é”®å­—å’Œè¿‡æ»¤å­—æ®µ
            keyword_list = [k.strip() for k in keywords.split('|') if k.strip()]
            fields_to_filter = [field.strip() for field in filter_fields.split('|') if field.strip()]

            def process_line(line: str) -> Optional[str]:
                """å¤„ç†å•è¡Œæ–‡æœ¬"""
                hay = line.lower() if ignore_case else line
                if any(k.lower() in hay if ignore_case else k in hay for k in keyword_list):
                    # å¤„ç†\nå­—ç¬¦è¿›è¡Œè½¬ä¹‰æ¢è¡Œ
                    processed_line = line.replace('\\n', '\n')
                    
                    if enable_field_filter and fields_to_filter:
                        for field in fields_to_filter:
                            field_pattern = field.lower() if ignore_case else field
                            hay = processed_line.lower() if ignore_case else processed_line
                            if field_pattern in hay:
                                start_idx = hay.find(field_pattern)
                                if start_idx >= 0:
                                    end_idx = start_idx + len(field)
                                    while end_idx < len(processed_line) and processed_line[end_idx] in ' :|\t':
                                        end_idx += 1
                                    processed_line = processed_line[:start_idx] + processed_line[end_idx:]
                    return processed_line
                return None

            # æ£€æŸ¥æ˜¯å¦æ˜¯å¤§æ–‡ä»¶
            is_large = FileHandler.is_large_file(input_path)
            if is_large and self.app:
                size, unit = FileHandler.get_file_size_info(input_path)
                self.app.log_info(f"ğŸ“¦ å¤„ç†å¤§æ–‡ä»¶: {size:.2f} {unit}")

            # å¤„ç†è¿›åº¦å›è°ƒ
            def on_progress(current: int, total: int):
                if self.app:
                    percent = (current / total) * 100 if total > 0 else 0
                    self.app.update_progress(f"å¤„ç†è¿›åº¦: {current}/{total} è¡Œ ({percent:.1f}%)")

            # å¤„ç†æ–‡ä»¶
            if preview_mode and self.app:
                content = []
                count_in = count_out = 0
                for chunk in FileHandler.read_in_chunks(input_path, read_enc):
                    for line in chunk.splitlines():
                        count_in += 1
                        result = process_line(line)
                        if result is not None:
                            content.append(result)
                            count_out += 1
                
                preview_content = '\n'.join(content)
                self.app.update_preview_content(preview_content)
                if keyword_list:  # åªæœ‰åœ¨æœ‰å…³é”®å­—çš„æƒ…å†µä¸‹æ‰è¿›è¡Œé«˜äº®
                    self.app._highlight_keywords(keyword_list, ignore_case)
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.app._update_system_info(f"é¢„è§ˆç»Ÿè®¡:\nè¯»å–: {count_in} è¡Œ\nåŒ¹é…: {count_out} è¡Œ")
                return (count_in, count_out)
            else:
                # æ­£å¸¸å¤„ç†æ¨¡å¼
                return FileHandler.process_large_file(
                    input_path,
                    output_path,
                    process_line,
                    encoding=read_enc,
                    callback=on_progress if is_large else None
                )

        except LookupError:
            if self.app:
                self.app.log_error(f"âŒ é”™è¯¯ï¼šä¸æ”¯æŒçš„ç¼–ç  '{read_enc}' æˆ– '{write_enc}'")
        except Exception as e:
            if self.app:
                self.app.log_error(f"âŒ å¤„ç†å‡ºé”™ {input_path.name}: {e}")
        return (0, 0)

    def batch_process(self, files: List[Path], output_dir: Path, **kwargs) -> None:
        """æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶"""
        try:
            total_files = len(files)
            self.processing_stats = {"total": 0, "matched": 0}  # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
            
            for i, input_path in enumerate(files, 1):
                if self.app:
                    self.app.log_info(f"ğŸ“„ å¤„ç†æ–‡ä»¶ ({i}/{total_files}): {input_path.name}")
                
                output_path = output_dir / f"{input_path.stem}_filtered{input_path.suffix}"
                count_in, count_out = self.filter_log(input_path, output_path, **kwargs)
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                if count_in > 0:
                    self.processing_stats["total"] += count_in
                    self.processing_stats["matched"] += count_out
                    
            # å¤„ç†å®Œæˆåçš„æ±‡æ€»ä¿¡æ¯
            if self.app and self.processing_stats["total"] > 0:
                percent = (self.processing_stats['matched'] / self.processing_stats['total'] * 100)
                self.app.log_info(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆ")
                self.app.log_info(f"   - æ€»è¡Œæ•°: {self.processing_stats['total']}")
                self.app.log_info(f"   - åŒ¹é…è¡Œæ•°: {self.processing_stats['matched']}")
                self.app.log_info(f"   - åŒ¹é…ç‡: {percent:.2f}%")
                
        except Exception as e:
            if self.app:
                self.app.log_error(f"âŒ æ‰¹é‡å¤„ç†å‡ºé”™: {e}")